# -*- coding: utf-8 -*-
"""MLDL_RGBD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ihki1PipyiKqkdph4JAn8ZsFK5PKUwqF

**Initialization**
"""

!pip3 install 'torch==1.3.1'
!pip3 install 'torchvision==0.5.0'
!pip3 install 'Pillow-SIMD'
!pip3 install 'tqdm'

# THIS IS THE NEW CORRECT NOTEBOOK
import os
import logging
import sys

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Subset, DataLoader
from torch.backends import cudnn

import torchvision
from torchvision import transforms
from torchvision import models
from torchvision import datasets

from PIL import Image
from tqdm import tqdm

import zipfile

from matplotlib import pyplot as plt
from matplotlib import cm
import numpy as np

from random import randint

import shutil

import time

from IPython.display import display

#The folowing parameters are the same as in the paper
DEVICE = 'cuda' # 'cuda' or 'cpu'
BATCH_SIZE = 64
LR = 3e-4
WEIGHT_DECAY = 0.05
MOMENTUM = 0.9

NUM_EPOCHS = 40

LAMBDA1 =  1     # weight of the PreTex task on the final loss
LAMBDA2 = 0.1    # weight of the loss of the target data contributing to the pretext loss

LOG_FREQUENCY = 20

ELAPSED_DA_EPOCHS = 0 # number of epochs of the restored DA checkpoint (useful for correctly restoring the num of epochs)
ELAPSED_SO_EPOCHS = 0 # number of epochs of the restored SO checkpoint (useful for correctly restoring the num of epochs)
DA_RESTORED = False   # Flags the retoration of a checkpoint --> allows retrieving list of lists of losses to which keep concatenatenating values for plotting
SO_RESTORED = False   # Flags the retoration of a checkpoint --> allows retrieving list of lists of losses to which keep concatenatenating values for plotting
V_RESTORED = False   # Flags the retoration of a checkpoint --> allows retrieving list of lists of losses to which keep concatenatenating values for plotting

EARLY_STOP_VAL = 10
NUM_BATCHES_LIMITED = 100 #(DEPRECATED since we do not use partial tests anymore)

SECOND_VARIATION = False  # <==== PERFORM VARIATION SELECTION HERE <==== (variation1:False ; variation2:True)

# Hyperparameters sets      (DOMAIN ADAPTATION)
# (LR, Lambda1, Lambda2)
s1 = (6e-4, 1, 0.1, 1)      # copy owned by MATTEO
s2 = (3e-4, 1, 0.1, 2)      # copy owned by JORDAN (values of the paper)
s3 = (3e-4, 2, 0.1, 3)      # copy owned by MATTEO
"""s4 = (6e-4, 1.5, 0.3, 4) # copy owned by JORDAN, keeps getting worse
s5 = (3e-5, 2, 0.3, 5)      # copy owned by DODO, very bad
s6 = (3e-5, 1.5, 0.3, 6)    # copy owned by DODO, still bad"""
s4 = (6e-4, 1, 0.3, 4)      # copy owned by JORDAN, substitute
s5 = (1e-4, 1, 0.05, 5)     # copy owned by DODO, first substitute
s6 = (1e-4, 0.75, 0.1, 6)   # copy owned by DODO, second substitute

"""s0 = (1e-4, 1.15, 0.05, 0) # this set was tested only once, later excluded
WEIGHT_DECAY = 0.01
BATCH_SIZE = 80"""

# Hyperparameters sets      (SOURCE ONLY)
#(Batch Size, LR, weight decay)
s7 = (64, 3e-4, 0.05, 7)        # copy owned by MATTEO (values of the paper)
s8 = (128, 3e-4, 0.05, 8)       # copy owned by JORDAN
s9 = (64, 6e-4, 0.05, 9)        # copy owned by MATTEO
s10 = (128, 6e-4, 0.005, 10)    # copy owned by JORDAN
s11 = (64, 3e-5, 0.005, 11)     # copy owned by DODO
s12 = (128, 3e-5, 0.005, 12)    # copy owned by DODO

# Hyperparameters sets      (VARIATION)
#(LR, Lambda1, Lambda2)
s13 = (3e-4, 1, 0.1, 13)         # (values of the paper)
s14 = (3e-4, 0.5, 0.1, 14)       # lower lambda1
s15 = (3e-4, 1.5, 0.1, 15)       # higher lambda1

selected_set = s7     # <=== PERFORM SELECTION HERE <===

if selected_set[3]<=6:
  LR = selected_set[0]
  LAMBDA1 = selected_set[1]
  LAMBDA2 = selected_set[2]
  print("Code set up for: DOMAIN ADAPTATION")
elif selected_set[3]<=12:
  BATCH_SIZE = selected_set[0]
  LR = selected_set[1]
  WEIGHT_DECAY = selected_set[2]
  print("Code set up for: SOURCE ONLY BASELINE")
else:
  LR = selected_set[0]
  LAMBDA1 = selected_set[1]
  LAMBDA2 = selected_set[2]
  print("Code set up for: VARIATION")

prefix = str(selected_set[3])

"""**Mount dataset from Google Drive and unzip it**

The drive is supposed to contain a folder called "datasets" that should contain ROD.zip and synROD.zip

(It is also supposed to store the checkpoints)
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# USE ONLY TO UNMOUNT DRIVE (useful when I/O errors occur)
from google.colab import drive
drive.flush_and_unmount()

"""Unzipping the dataset"""

# known integration error among colab and drive: https://research.google.com/colaboratory/faq.html#drive-timeout.
# No clear solution. Some suggest there might be a limit on how many times we can access files on drive every day.

with zipfile.ZipFile("./drive/My Drive/datasets/synROD.zip", 'r') as zip_ref:
    zip_ref.extractall("./dataset_unzipped/")

with zipfile.ZipFile("./drive/My Drive/datasets/ROD.zip", 'r') as zip_ref:
    zip_ref.extractall("./dataset_unzipped/")

print("DONE!")

"""**ALTERNATIVE**, **for when IO Errors occur**

Alternative that can be tested when errors occur (substitutes both the mount and unzip blocks above)
"""

print("ROD")
# download from drive
!gdown https://drive.google.com/uc?id=1s4D9vy5uTrgHpuwvgcBabRQbGXa3XXJK&export=download
# unzip
with zipfile.ZipFile("/content/ROD.zip", 'r') as zip_ref:
    zip_ref.extractall("./dataset_unzipped/")
# remove the zip, due to disk limitations
!rm -f ROD.zip

print("synROD")
# download from drive
!gdown https://drive.google.com/uc?id=1N8H_yqbrVl7DFdMqheHhfu4waT71YL-E&export=download
# unzip
with zipfile.ZipFile("/content/synROD.zip", 'r') as zip_ref:
    zip_ref.extractall("./dataset_unzipped/")
# remove the zip
!rm -f synROD.zip

"""**Import external code from GitHub repo**"""

# Clone github repository with data
if not os.path.isdir('./MLDL_RGBD_project'):
  !git clone https://github.com/MatteGarba/MLDL_RGBD_project.git
  #!mv 'MLDL_RGBD_project' 

from MLDL_RGBD_project.models import PreText, PreText_variation, MainTask, FeatureExtractor

"""**Reshaping, checking and fixing the datasets**

Performs data preprocessing as described in the report, but basically reshapes the dataset making it suitable for ImageFolder, removes decoupled images and discards 4 underrepresented classes
"""

from MLDL_RGBD_project.dataset_handler import Dataset_handler

d = Dataset_handler()

print("Reshaping the datasets")
d.reshape()

print() 

print("Checking synROD:")
d.check('/content/dataset_rgb_synROD','/content/dataset_depth_synROD')
d.fix('/content/dataset_rgb_synROD','/content/dataset_depth_synROD')

print()

print("Checking ROD:")
d.check('/content/dataset_rgb_ROD','/content/dataset_depth_ROD')
d.fix('/content/dataset_rgb_ROD','/content/dataset_depth_ROD')

"""**Preparing the dataset**

Apply the splits:
"""

def restrict_imagefolder(imagefolder, removed_pictures, is_rgb=True):
  """
  Remove the images that do not belong to the considered split from the attributes of ImageFolder. 
  """
  # build a set to check if a path should be excluded or not
  with open(removed_pictures, 'r') as f:
    removed_paths = set()
    if is_rgb:
      modality='rgb'
    else:
      modality='depth'
    for line in f.readlines():
      starting_path = (line.split(' '))[0]                                  # 'apple/rgb/apple_1_05_00002009.png'
      pieces = starting_path.split('/')
      final_path = f"/content/dataset_{modality}_synROD/{pieces[0]}/{pieces[2]}"   # '/content/dataset_rgb_synROD/apple/apple_1_05_00002009.png
      removed_paths.add(final_path)

  # remove all samples from imagefolder that appear in the set, and also the targets attribute
  filtered_indices = [i for i, sample in enumerate(imagefolder.samples) if sample[0] not in removed_paths]
  filtered_samples = [imagefolder.samples[i] for i in filtered_indices]
  filtered_targets = [imagefolder.targets[i] for i in filtered_indices]
  
  # use the filtered lists as attributes for ImageFolder
  imagefolder.samples = filtered_samples
  imagefolder.targets = filtered_targets
  imagefolder.imgs = imagefolder.samples
  return imagefolder

"""Continue towards dataloaders preparation by means of:


1.   Define transforms (ad-hoc class)
2.   Create ImageFolders (eventually restricted)

continues...
"""

from MLDL_RGBD_project.rgb_depth_pairs import DualDataset, DualRandomHFlip, DualRandomCrop, dual, DualCompose

# Define transforms for the datasets
test_transform = DualCompose([dual(transforms.Resize(256), is_dual = False),      # Resizes short size of the PIL image to 256
                    dual(transforms.CenterCrop(224), is_dual = False),  # Crops a central square patch of the image
                                                                 # 224 because torchvision's ResNet18 needs a 224x224 input!
                    dual(transforms.ToTensor(), is_dual = False),      # Turn PIL Image to torch.Tensor
                    dual(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), is_dual = False) # Normalizes tensor with mean and standard deviation
])
my_transforms = DualCompose([dual(transforms.Resize(256), is_dual=False),
                    dual(DualRandomCrop(224), is_dual=True),
                    dual(DualRandomHFlip(p=0.5), is_dual=True),
                    dual(transforms.ToTensor(), is_dual=False),
                    dual(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), is_dual=False)
])

# create ImageFolders
data_folder = "/content/dataset_rgb_synROD"
data_synRODrgb = datasets.ImageFolder(root = data_folder)
data_synRODrgb = restrict_imagefolder(data_synRODrgb, '/content/dataset_unzipped/synROD/synARID_50k-split_rgb_test1.txt', is_rgb=True)  # remove the testing ones

test_synRODrgb = datasets.ImageFolder(root = data_folder)
test_synRODrgb = restrict_imagefolder(test_synRODrgb, '/content/dataset_unzipped/synROD/synARID_50k-split_rgb_train1.txt', is_rgb=True) # remove the training part

data_folder = "/content/dataset_depth_synROD"
data_synRODdepth = datasets.ImageFolder(root = data_folder)
data_synRODdepth = restrict_imagefolder(data_synRODdepth, '/content/dataset_unzipped/synROD/synARID_50k-split_depth_test1.txt', is_rgb=False)  # remove the testing ones

test_synRODdepth = datasets.ImageFolder(root = data_folder)
test_synRODdepth = restrict_imagefolder(test_synRODdepth, '/content/dataset_unzipped/synROD/synARID_50k-split_depth_train1.txt', is_rgb=False) # remove the training part

data_folder = "/content/dataset_rgb_ROD"
data_RODrgb = datasets.ImageFolder(root = data_folder)

data_folder = "/content/dataset_depth_ROD"
data_RODdepth = datasets.ImageFolder(root = data_folder)

"""...here we go:
3.   Allocate dataset object DualDataset (cool class :-) )
4.   Define the base (not transformed dataloaders)

(sorry for the UGLY typo "dataloarder", it was too widespreaded to correct it)
"""

#Source for training
source_data = DualDataset(data_synRODrgb, data_synRODdepth, False, dual_transforms=my_transforms)
source_dataloarder = torch.utils.data.DataLoader(source_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)

#Target for training
train_target_data = DualDataset(data_RODrgb, data_RODdepth, False, dual_transforms=my_transforms)
train_target_dataloarder = torch.utils.data.DataLoader(train_target_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)

#Target for test
test_target_data = DualDataset(data_RODrgb, data_RODdepth, False, dual_transforms=test_transform)
test_target_dataloarder = torch.utils.data.DataLoader(test_target_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)

"""
#Source for test (deprecated)
source_test_data = DualDataset(test_synRODrgb, test_synRODdepth, flag_rotate=False, dual_transforms=my_transforms)
source_test_dataloarder = torch.utils.data.DataLoader(source_test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)
"""

# These are defined as functions because the desired transformation (rotate/permute)
# is embedded in the dual dataset definition, thus it's required to re-define
# them at each epoch in order to constantly change the relative rotations/permutations

def get_rotated_dataLoader(data_synRODrgb, data_synRODdepth, data_RODrgb, data_RODdepth):
  #Rotated Datasets 
  source_rotated_data = DualDataset(data_synRODrgb, data_synRODdepth, True, dual_transforms=my_transforms)
  target_rotated_data = DualDataset(data_RODrgb, data_RODdepth, True, dual_transforms=my_transforms)
  #Rotated Dataloader
  source_rotated_dataloarder = torch.utils.data.DataLoader(source_rotated_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)
  target_rotated_dataloarder = torch.utils.data.DataLoader(target_rotated_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)
  return source_rotated_dataloarder,target_rotated_dataloarder

def get_permuted_dataLoader(data_synRODrgb, data_synRODdepth, data_RODrgb, data_RODdepth, v2=False):
  #Permuted Datasets 
  source_permuted_data = DualDataset(data_synRODrgb, data_synRODdepth, False, dual_transforms=my_transforms, flag_permute=True, variation2=v2)
  target_permuted_data = DualDataset(data_RODrgb, data_RODdepth, False, dual_transforms=my_transforms, flag_permute=True, variation2=v2)
  #Permuted Dataloader
  source_permuted_dataloarder = torch.utils.data.DataLoader(source_permuted_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)
  target_permuted_dataloarder = torch.utils.data.DataLoader(target_permuted_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)
  return source_permuted_dataloarder,target_permuted_dataloarder

"""**Validation and Test function**

Called at the end of each epoch to run a test phase. It can be used for a partial test (portion of Target) or for a complete test depending on the "test_phase" flag. In the end is always used for complete tests due to a big difference in the results making them uncomparable.
"""

def validation_test(extractor, maintask, dataloader, criterion, test_phase):
  # i perform the model evaluation after each epoch
  running_corrects = 0
  loss_val = 0.0
  extractor.eval()
  maintask.eval()
  batch_n = 0

  with torch.no_grad():
    for (rgb, depth), labels in tqdm(dataloader):
      batch_n += 1
      rgb = rgb.to(DEVICE)
      depth = depth.to(DEVICE)
      labels = labels.to(DEVICE)
      #make predictions
      features = extractor.forward(rgb, depth)
      outputs = maintask.forward(features)
      #get the validation loss for each batch
      loss_val += criterion(outputs, labels).item()*len(rgb)
      # Get predictions
      _, preds = torch.max(outputs.data, 1) 

      # Update Corrects
      running_corrects += torch.sum(preds == labels.data).data.item()
      # stop at batch number 100 if test_phase = True
      if batch_n == NUM_BATCHES_LIMITED and test_phase == False:
        break

  if test_phase == False:
    length = NUM_BATCHES_LIMITED*BATCH_SIZE
  else:
    length = len(dataloader.dataset)
  
  return float(loss_val)/ float(length), float(running_corrects)/ float(length)

"""**----- SOURCE-ONLY BASELINE -----**

Define the base models
"""

# Model components
Extractor1 = FeatureExtractor().to(DEVICE)
mainTask1 = MainTask().to(DEVICE)

"""Prepare training"""

# Optimizers
extractor1_opt = optim.SGD(Extractor1.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
mainTask1_opt = optim.SGD(mainTask1.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)

"""**Define checkpoint methods**

The checkpoint life:


*   When saving: saved on colab and copied in drive
*   When loading: copied in colab from drive and read
"""

"""
so_checkpoint = {'Extractor': Extractor,
                'mainTask': mainTask,
          'Extractor_state_dict': Extractor.state_dict(),
          'mainTask_state_dict': mainTask.state_dict(),
                'extractor_opt': extractor_opt,
                'mainTask_opt': mainTask_opt,
          'Extractor_optimizer' : extractor_opt.state_dict(),
          'mainTask_optimizer' : mainTask_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
"""

DRIVEPATH = "/content/drive/My Drive/"
LOCALPATH = "/content/checkpoints/"
SO_CHECKPOINT = "so_checkpoint.pth"

# Function loading a checkpoint
def load_so_checkpoint(prefix=""):

  if not os.path.isdir("/content/checkpoints"):           # create local destination if doesn't exist
    !mkdir /content/checkpoints
  
  if os.path.exists(DRIVEPATH+str(prefix)+SO_CHECKPOINT) and os.path.isfile(DRIVEPATH+str(prefix)+SO_CHECKPOINT): # if checkpoint file existst and is a file
    shutil.copyfile(DRIVEPATH+str(prefix)+SO_CHECKPOINT, LOCALPATH+str(prefix)+SO_CHECKPOINT)                     # copy it locally
  else:
    sys.exit(-1)
  
  checkpoint = torch.load(LOCALPATH+str(prefix)+SO_CHECKPOINT)                                                    # load it from local copy

  Extractor = checkpoint['Extractor']
  mainTask = checkpoint['mainTask']
  extractor_opt = checkpoint['extractor_opt']
  mainTask_opt = checkpoint['mainTask_opt']

  Extractor.load_state_dict(checkpoint['Extractor_state_dict'])
  mainTask.load_state_dict(checkpoint['mainTask_state_dict'])
  extractor_opt.load_state_dict(checkpoint['Extractor_optimizer'])
  mainTask_opt.load_state_dict(checkpoint['mainTask_optimizer'])

  print(f"Restored checkpoint at epoch: {checkpoint['epoch']}")

  return Extractor, mainTask, extractor_opt, mainTask_opt,\
         checkpoint['epoch'], checkpoint['lossesLists'], checkpoint['val_accuracy'],\
         checkpoint['additional_data'], checkpoint['main_checkpoints']


def save_so_checkpoint(checkpoint, prefix=""):

  if not os.path.isdir("/content/checkpoints"):     # create local source folder
    !mkdir /content/checkpoints                 
    
  torch.save(checkpoint, LOCALPATH+str(prefix)+SO_CHECKPOINT)

  if os.path.exists(DRIVEPATH):                                                               # if drive is mounted
    shutil.copyfile(LOCALPATH+str(prefix)+SO_CHECKPOINT, DRIVEPATH+str(prefix)+SO_CHECKPOINT) # copy checkpoint file from local to drive
    print("Checkpoint saved")
  else:
    sys.exit(-1)

"""Load a checkpoint

WARNING: overwrites *Define the base models* and *Prepare training*
"""

# this is use for the back up
# WARNING: run this block only if you want to load the saved parameters (OVERWRITES PREVIOUS CELLS)
Extractor1, mainTask1, extractor1_opt, mainTask1_opt, ELAPSED_SO_EPOCHS, lossesLists,\
                                            val_accuracy, additional_data, main_checkpoints = load_so_checkpoint(prefix=prefix)
SO_RESTORED = True

"""Train"""

# Losses
mainTask1_criterion = nn.CrossEntropyLoss() # criterion Lm

start_time = time.time()
 
cudnn.benchmark                                    # Calling this optimizes runtime
 
if SO_RESTORED:                                    # if a checkpoint was loaded
  Src_mainLoss = lossesLists[0]                       # restore the previous losses lists
  epochs_no_improve = additional_data[0]
  min_val_loss = additional_data[1]
  best_epoch = additional_data[2]
  # val_accuracy is already restored
  # main_checkpoints is already restored
else:                                              # otherwise use some new ones
  Src_mainLoss = []
  val_accuracy = []
  epochs_no_improve = 0
  min_val_loss = np.Inf
  best_epoch = 0
  main_checkpoints = []
 
 
n_epochs_stop = EARLY_STOP_VAL
flag_stop = False
epoch = ELAPSED_SO_EPOCHS + 1
 
while epoch <= NUM_EPOCHS:
  if flag_stop == True:
    break
  print('Starting epoch {}/{}'.format(epoch , NUM_EPOCHS))
 
  torch.cuda.empty_cache()
  Extractor1.train(True)                                 # set in training mode
  mainTask1.train(True)                                  # set in training mode
 
  cumsum_mainloss = 0
  current_step = 0
 
  # Work on Source dataset only
  for S in source_dataloarder:
 
    # Forward pass - Source:
    (S_rgb_image, S_depth_image), S_label = S                 # load Source batch
 
    S_rgb_batch = S_rgb_image.to(DEVICE)                      # bring data over device
    S_depth_batch = S_depth_image.to(DEVICE)                  # bring data over device
    S_label = S_label.to(DEVICE)                              # bring label over device
 
    S_features = Extractor1.forward(S_rgb_batch, S_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask1.forward(S_features)                 # main task forward pass
    S_main_loss = mainTask1_criterion(outPuts_main, S_label)       # compute main loss
    cumsum_mainloss += S_main_loss.item()*len(S_rgb_image)        # loss for all the images in S_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE --> Step {}, Loss {}'.format(current_step, S_main_loss.item()))
 
 
    # final steps
    Extractor1.zero_grad()             # Zero-ing the gradients
    mainTask1.zero_grad()              # Zero-ing the gradients
 
    S_main_loss.backward()             # backward pass: computes gradients for the net
 
    extractor1_opt.step()              # update weights for extractor
    mainTask1_opt.step()               # update the weights of the only maintask
 
    current_step += 1
  
 
  #list of losses for the source dataset over the main classifier for later visualization
  Src_mainLoss.append(cumsum_mainloss / float(len(source_dataloarder.dataset)))
 
 
  # each 5 epochs do a complete validation/test phase on the target dataset
  #otherwise do it on 100 batches only for all the other epochs
  """big_test = False
  if epoch != 0 and epoch % 5 == 0:
    big_test = True"""
  # Not entirely representative of the actual performance in quick validations. Let's do a complete one each epoch
  big_test = True
 
  loss , acc = validation_test(Extractor1, mainTask1, test_target_dataloarder, mainTask1_criterion, test_phase = big_test)
  val_accuracy.append(acc)
  print(f"VALIDATION ACCURACY: {acc}")
 
 
  # early stopping criterion
  if loss < min_val_loss:       # if there was an improvement in the loss --> reset counter
    epochs_no_improve = 0
    min_val_loss = loss
    best_epoch = epoch
  else:                       # Otherwise increment count of epochs with no improvement
    epochs_no_improve += 1
    # Check early stopping condition
    if epochs_no_improve >= n_epochs_stop:
      print(f'\nEarly stopping! at epoch {epoch}.\n The best epoch is epoch {best_epoch}')
      flag_stop = True
 
 
  # save the model at each epoch end
  lossesLists = [Src_mainLoss] # list of losses lists
  additional_data = [epochs_no_improve, min_val_loss, best_epoch]            # list of important params to save
  
  checkpoint = {'Extractor': Extractor1,
                'mainTask': mainTask1,
          'Extractor_state_dict': Extractor1.state_dict(),
          'mainTask_state_dict': mainTask1.state_dict(),
                'extractor_opt': extractor1_opt,
                'mainTask_opt': mainTask1_opt,
          'Extractor_optimizer' : extractor1_opt.state_dict(),
          'mainTask_optimizer' : mainTask1_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
 
  if epoch != 0 and epoch % 5 == 0:
    # each 5 epochs save the checkpoint in the main checkpoints list
    main_checkpoint = dict()  # create an independent copy
    for k in checkpoint:
      if k != 'main_checkpoints': # clear this for memory purposes
        main_checkpoint[k] = checkpoint[k]
      else:
        main_checkpoint[k] = None

    checkpoint['main_checkpoints'].append(main_checkpoint)
 
  save_so_checkpoint(checkpoint, prefix=prefix)
  
  # save the checkpoint
  
  exec_time = time.time() - start_time
  mins = int(exec_time // 60)
  secs = int(exec_time % 60)
  print(f"--- Elapsed time from trainig start (eventual checkpoint restoration excluded): {mins} minutes and {secs} seconds ---")
  epoch +=1
  # --- epoch end ---

"""Test"""

loss, accuracy = validation_test(Extractor1, mainTask1, test_target_dataloader, mainTask1_criterion, True)
print('The test loss is {:.2f}, and accuracy {:.2f}'.format{loss, accuracy})

"""**----- DOMAIN-ADAPTATION -----**

**Define the base models**
"""

Extractor = FeatureExtractor().to(DEVICE)
mainTask = MainTask().to(DEVICE)
preText = PreText().to(DEVICE)

"""**Prepare training**"""

# Optimizer
extractor_opt = optim.SGD(Extractor.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
mainTask_opt = optim.SGD(mainTask.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
preText_opt = optim.SGD(preText.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)

"""**Define checkpoint methods**

The checkpoint life:


*   When saving: saved on colab and copied in drive
*   When loading: copied in colab from drive and read
"""

"""
da_checkpoint = {'Extractor': Extractor,
                'mainTask': mainTask,
                'preText': preText,
          'Extractor_state_dict': Extractor.state_dict(),
          'mainTask_state_dict': mainTask.state_dict(),
          'preText_state_dict': preText.state_dict(),
                'extractor_opt': extractor_opt,
                'mainTask_opt': mainTask_opt,
                'preText_opt': preText_opt,
          'Extractor_optimizer' : extractor_opt.state_dict(),
          'mainTask_optimizer' : mainTask_opt.state_dict(),
          'preText_optimizer' : preText_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
"""

DRIVEPATH = "/content/drive/My Drive/"
LOCALPATH = "/content/checkpoints/"
DA_CHECKPOINT = "da_checkpoint.pth"

# Function loading a checkpoint
def load_da_checkpoint(prefix=""):

  if not os.path.isdir("/content/checkpoints"): # create destination
    !mkdir /content/checkpoints
  
  if os.path.exists(DRIVEPATH+str(prefix)+DA_CHECKPOINT) and os.path.isfile(DRIVEPATH+str(prefix)+DA_CHECKPOINT): # if f existst and is a file
    shutil.copyfile(DRIVEPATH+str(prefix)+DA_CHECKPOINT, LOCALPATH+str(prefix)+DA_CHECKPOINT)                     # copy it locally
  else:
    raise RuntimeError("Cannot find the checkpoint file. Have you loaded the drive with the dataset? Have you chosen the right hyperparameter set?")
  
  checkpoint = torch.load(LOCALPATH+str(prefix)+DA_CHECKPOINT)                                        # load it from local copy

  Extractor = checkpoint['Extractor']
  mainTask = checkpoint['mainTask']
  preText = checkpoint['preText']
  extractor_opt = checkpoint['extractor_opt']
  mainTask_opt = checkpoint['mainTask_opt']
  preText_opt = checkpoint['preText_opt']

  Extractor.load_state_dict(checkpoint['Extractor_state_dict'])
  mainTask.load_state_dict(checkpoint['mainTask_state_dict'])
  preText.load_state_dict(checkpoint['preText_state_dict'])
  extractor_opt.load_state_dict(checkpoint['Extractor_optimizer'])
  mainTask_opt.load_state_dict(checkpoint['mainTask_optimizer'])
  preText_opt.load_state_dict(checkpoint['preText_optimizer'])

  print(f"Restored checkpoint at epoch: {checkpoint['epoch']}")

  return Extractor, mainTask, preText, extractor_opt, mainTask_opt, preText_opt,\
         checkpoint['epoch'], checkpoint['lossesLists'], checkpoint['val_accuracy'], checkpoint['additional_data'], checkpoint['main_checkpoints']


def save_da_checkpoint(checkpoint, prefix=""):

  if not os.path.isdir("/content/checkpoints"): # create source
    !mkdir /content/checkpoints                 
    
  torch.save(checkpoint, LOCALPATH+str(prefix)+DA_CHECKPOINT)

  if os.path.exists(DRIVEPATH): # if f existst and is a file
    shutil.copyfile(LOCALPATH+str(prefix)+DA_CHECKPOINT, DRIVEPATH+str(prefix)+DA_CHECKPOINT) # copy it locally
    print("Checkpoint saved")
  else:
    raise RuntimeError("Cannot find the checkpoint file. Have you loaded the drive with the dataset? Have you chosen the right hyperparameter set?")

"""Load a checkpoint:

WARNING: overwrites *Define the base models* and *Prepare training*
"""

# this is use for the back up
# WARNING: run this block only if you want to load the saved parameters (OVERWRITES PREVIOUS CELLS)
Extractor, mainTask, preText, extractor_opt, mainTask_opt, preText_opt, ELAPSED_DA_EPOCHS, lossesLists,\
                                            val_accuracy, additional_data, main_checkpoints = load_da_checkpoint(prefix=prefix)
DA_RESTORED = True

"""**Domain adaptation - Training procedure**"""

# Losses
mainTask_criterion = nn.CrossEntropyLoss() # criterion Lm
src_preText_criterion = nn.CrossEntropyLoss()  # criterion Lp
tgt_preText_criterion = nn.CrossEntropyLoss()  # criterion Lp
# 
# Entropy loss for the target on main task
def tgt_main_criterion(logits):
    p_softmax = F.softmax(logits, dim=1)
    mask = p_softmax.ge(0.000001)  # greater or equal to, used for numerical stability
    mask_out = torch.masked_select(p_softmax, mask)
    entropy = -(torch.sum(mask_out * torch.log(mask_out)))
    return entropy / float(p_softmax.size(0))

start_time = time.time()
 
cudnn.benchmark                                    # Calling this optimizes runtime
 
if DA_RESTORED:                                    # if a checkpoint was loaded
  Src_mainLoss = lossesLists[0]                       # restore the previous losses lists
  tgt_mainLoss = lossesLists[1]
  Src_rotateLoss = lossesLists[2]
  tgt_rotateLoss = lossesLists[3]
  epochs_no_improve = additional_data[0]
  min_val_loss = additional_data[1]
  best_epoch = additional_data[2]
  # val_accuracy is already restored
  # main_checkpoints is already restored
else:                                              # otherwise use some new ones
  Src_mainLoss = []
  tgt_mainLoss = []
  Src_rotateLoss = []
  tgt_rotateLoss = []
  val_accuracy = []
  epochs_no_improve = 0
  min_val_loss = np.Inf
  best_epoch = 0
  main_checkpoints = []
 
 
n_epochs_stop = EARLY_STOP_VAL
flag_stop = False
epoch = ELAPSED_DA_EPOCHS + 1
 
while epoch <= NUM_EPOCHS:
  if flag_stop == True:
    break
  print('Starting epoch {}/{}'.format(epoch , NUM_EPOCHS))
 
  # Data loaders:
  source_rotated_dataloader,target_rotated_dataloader = get_rotated_dataLoader(data_synRODrgb,\
                                                    data_synRODdepth, data_RODrgb, data_RODdepth)
  
  torch.cuda.empty_cache()
  Extractor.train(True)                                 # set in training mode
  mainTask.train(True)                                  # set in training mode
  preText.train(True)                                   # set in training mode
 
  cumsum_mainloss = 0
  cumsum_T_mainloss = 0
  cumsum_Trloss = 0
  cumsum_Srloss = 0
  current_step = 0
 
  # Work on 3 batches in parallel
  for S, T, Sr, Tr in zip(source_dataloarder, train_target_dataloarder, source_rotated_dataloader, target_rotated_dataloader):
  
 
 
    # Forward pass - Source:
    (S_rgb_image, S_depth_image), S_label = S                 # load Source batch
 
    S_rgb_batch = S_rgb_image.to(DEVICE)                      # bring data over device
    S_depth_batch = S_depth_image.to(DEVICE)                  # bring data over device
    S_label = S_label.to(DEVICE)                              # bring label over device
 
    S_features = Extractor.forward(S_rgb_batch, S_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(S_features)                 # main task forward pass
    S_main_loss = mainTask_criterion(outPuts_main, S_label)       # compute main loss
    cumsum_mainloss += S_main_loss.item()*len(S_rgb_image)        # loss for all the images in S_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE --> Step {}, Loss {}'.format(current_step, S_main_loss.item()))
 
 
 
    # Forward pass - Target:
    (T_rgb_image, T_depth_image), T_label = T                 # load Source batch
 
    T_rgb_batch = T_rgb_image.to(DEVICE)                      # bring data over device
    T_depth_batch = T_depth_image.to(DEVICE)                  # bring data over device
                                                              # DON'T use the labels
 
    T_features = Extractor.forward(T_rgb_batch, T_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(T_features)                 # main task forward pass
    T_main_loss = tgt_main_criterion(outPuts_main)              # compute main loss of Target on MainTask
    cumsum_T_mainloss += T_main_loss.item()*len(T_rgb_image)           # loss for all the images in T_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('TARGET --> Step {}, Loss {}'.format(current_step, T_main_loss.item()))
 
 
 
    # Forward pass - Source rotated
    (Sr_rgb_image, Sr_depth_image), Sr_label = Sr               # load Source rotated batch
 
    Sr_rgb_batch = Sr_rgb_image.to(DEVICE)                      # bring data over device
    Sr_depth_batch = Sr_depth_image.to(DEVICE)                  # bring data over device
    Sr_label = Sr_label.to(DEVICE)                              # bring label over device
 
    Sr_features = Extractor.forward(Sr_rgb_batch, Sr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Sr_features)                     # preText task forward pass
    Sr_loss = src_preText_criterion(out_preText, Sr_label)         # compute aux loss 
    cumsum_Srloss += Sr_loss.item()*len(Sr_rgb_image)              # loss for all the images in Sr_rgb_image
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE ROT --> Step {}, Loss {}'.format(current_step, Sr_loss.item()))
 
 
 
    # Forward pass - Target rotated
    (Tr_rgb_image, Tr_depth_image), Tr_label = Tr               # load Source rotated batch
 
    Tr_rgb_batch = Tr_rgb_image.to(DEVICE)                      # bring data over device
    Tr_depth_batch = Tr_depth_image.to(DEVICE)                  # bring data over device
    Tr_label = Tr_label.to(DEVICE)                              # bring the label to device 
 
    Tr_features = Extractor.forward(Tr_rgb_batch, Tr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Tr_features)                     # preText task forward pass
    Tr_loss = tgt_preText_criterion(out_preText, Tr_label)                   # compute aux loss (entropy loss)
    cumsum_Trloss += Tr_loss.item()*len(Tr_rgb_image)              # loss for all the images in Tr_rgb_image
 
    if current_step % LOG_FREQUENCY == 0:
      print('TARGET ROT --> Step {}, Loss {}'.format(current_step, Tr_loss.item()))
 
 
    # computing final loss
    final_loss = S_main_loss + LAMBDA1 * (Sr_loss +  Tr_loss) + LAMBDA2 * T_main_loss
 
    if current_step % LOG_FREQUENCY == 0:
      print('TOTAL LOSS --> Step {}, Loss {}'.format(current_step, final_loss.item()))
      print()
 
    # final steps
    Extractor.zero_grad()             # Zero-ing the gradients
    mainTask.zero_grad()              # Zero-ing the gradients
    preText.zero_grad()               # Zero-ing the gradients
 
    final_loss.backward()             # backward pass: computes gradients for the net
 
    preText_opt.step()                # update weights for pretext
    extractor_opt.step()              # update weights for extractor
    mainTask_opt.step()               # update the weights of the only maintask
 
    current_step += 1
  
 
  #list of losses for the source dataset over the main classifier for later visualization
  Src_mainLoss.append(cumsum_mainloss / float(len(source_dataloarder.dataset))) 
  tgt_mainLoss.append(cumsum_T_mainloss / float(len(train_target_dataloarder.dataset))) 
  Src_rotateLoss.append(cumsum_Srloss / float(len( source_rotated_dataloader.dataset)))
  tgt_rotateLoss.append(cumsum_Trloss / float(len(target_rotated_dataloader.dataset)))
 
 
  # each 5 epochs do a complete validation/test phase on the target dataset
  #otherwise do it on 100 batches only for all the other epochs
  """big_test = False
  if epoch != 0 and epoch % 5 == 0:
    big_test = True"""
  # Not entirely representative of the actual performance in quick validations. Let's do a complete one each epoch
  big_test = True
 
  loss , acc = validation_test(Extractor, mainTask, test_target_dataloarder, mainTask_criterion, test_phase = big_test)
  val_accuracy.append(acc)
  print(f"\nVALIDATION ACCURACY: {acc}")
  print(f"VALIDATION Loss: {loss}")
 
 
  # early stopping criterion
  if loss < min_val_loss:       # if there was an improvement in the loss --> reset counter
    epochs_no_improve = 0
    min_val_loss = loss
    best_epoch = epoch
  else:                       # Otherwise increment count of epochs with no improvement
    epochs_no_improve += 1
    # Check early stopping condition
    if epochs_no_improve >= n_epochs_stop:
      print(f'\nEarly stopping! at epoch {epoch}.\n The best epoch is epoch {best_epoch}')
      flag_stop = True
 
 
  # save the model at each epoch end
  lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss] # list of losses lists
  additional_data = [epochs_no_improve, min_val_loss, best_epoch]            # list of important params to save
  
  checkpoint = {'Extractor': Extractor,
                'mainTask': mainTask,
                'preText': preText,
          'Extractor_state_dict': Extractor.state_dict(),
          'mainTask_state_dict': mainTask.state_dict(),
          'preText_state_dict': preText.state_dict(),
                'extractor_opt': extractor_opt,
                'mainTask_opt': mainTask_opt,
                'preText_opt': preText_opt,
          'Extractor_optimizer' : extractor_opt.state_dict(),
          'mainTask_optimizer' : mainTask_opt.state_dict(),
          'preText_optimizer' : preText_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
 
  if epoch != 0 and epoch % 5 == 0:
    # each 5 epochs save the checkpoint in the main checkpoints list
    main_checkpoint = dict()  # create an independent copy
    for k in checkpoint:
      if k != 'main_checkpoints': # clear this for memory purposes
        main_checkpoint[k] = checkpoint[k]
      else:
        main_checkpoint[k] = None

    checkpoint['main_checkpoints'].append(main_checkpoint)
 
  save_da_checkpoint(checkpoint, prefix=prefix)
  
  # save the checkpoint
  
  exec_time = time.time() - start_time
  mins = int(exec_time // 60)
  secs = int(exec_time % 60)
  print(f"--- Elapsed time from trainig start (eventual checkpoint restoration excluded): {mins} minutes and {secs} seconds ---\n")
  epoch +=1
  # --- epoch end ---

"""Test"""

loss, accuracy = validation_test(Extractor, mainTask, test_target_dataloarder, mainTask_criterion, test_phase = True)
print('The test loss is {:.2f}, and accuracy {:.2f}'.format(loss, accuracy))

"""**Analyse results**"""

def simple_plot(x, y, title=None, x_label=None, y_label=None):
  fig, ax = plt.subplots(figsize=(10,8))

  ax.plot(x, y, c='red')

  if title is not None:
    plt.title(title)

  if x_label is not None:
    plt.xlabel(x_label)

  if y_label is not None:
    plt.ylabel(y_label)

  plt.ylim(0, 1) # remove this if it's not an accuracy
  plt.show()

import numpy as np


def big_plot(curves, title, ylabel=None):
  fig, ax = plt.subplots(figsize=(12,10))

  x_max = 0

  for c in curves:
    ax.plot(c['x'], c['y'], c=c['color'], label=c['label'])

    if len(c['x']) > x_max:
      x_max = len(c['x']) #fixed

  x_ticks = range(1, x_max+1)
  plt.xticks(x_ticks)

  

  ax.grid(True)

  plt.title(title)

  plt.xlabel("Epoch")

  if ylabel is None:
    plt.ylim(0, 1)
    y_ticks = np.arange(0, 1.1, 0.1)
    plt.yticks(y_ticks)
    plt.ylabel("Accuracy")
  else:
    plt.ylabel(ylabel)

  plt.legend(loc="lower right")
  ax.legend()
  plt.show()

# Domain Adaptation results

models_to_plot = [1, 2, 3, 4, 5, 6]


colorlist = ['black', 'gray', 'lightcoral', 
'saddlebrown', 'red', 'darkorange', 
'gold', 'olivedrab', 'lime', 
'turquoise', 'dodgerblue', 'darkslateblue',
'blueviolet', 'violet', 'yellow']

curves = []

for i in models_to_plot: 
  
  prefix = str(i)

  _, _, _, _, _, _, _, _, val_accuracy, _, main_checkpoints = load_da_checkpoint(prefix)

  best_acc = max(val_accuracy)
  best_epoch = val_accuracy.index(best_acc)+1

  label = f"Set {i} (best {(best_acc // 0.0001)/100} at epoch {best_epoch})"

  screenshot = {'x': range(1, len(val_accuracy)+1), 'y': val_accuracy, 
                'label': label, 'color': colorlist[i]}

  curves.append(screenshot)


big_plot(curves, "Domain adaptation models performances")

# Source only baseline results

models_to_plot = [7, 8, 9, 10, 11, 12]


colorlist = ['black', 'gray', 'lightcoral', 
'saddlebrown', 'red', 'darkorange', 
'gold', 'olivedrab', 'lime', 
'turquoise', 'dodgerblue', 'darkslateblue',
'blueviolet', 'violet', 'yellow']

curves = []

for i in models_to_plot: 

  prefix = str(i)
  _, _, _, _, _, _, val_accuracy, _, main_checkpoints = load_so_checkpoint(prefix=prefix)

  best_acc = max(val_accuracy)
  best_epoch = val_accuracy.index(best_acc)+1

  label = f"Set {i} (best {(best_acc // 0.0001)/100} at epoch {best_epoch})"

  screenshot = {'x': range(1, len(val_accuracy)+1), 'y': val_accuracy, 
                'label': label, 'color': colorlist[i]}

  curves.append(screenshot)

  #print(f"Checkpoint {prefix} accuracies:")
  #simple_plot(range(1, len(val_accuracy)+1), val_accuracy, f"Accuracy of hyperparameters set {prefix} (best {best_acc} at epoch {best_epoch})", "Epoch", "Accuracy")
  #print()

big_plot(curves, "Source Only baseline models performances")

from MLDL_RGBD_project.FeatureVisualization import FeatureVisualization

visualizer = FeatureVisualization()
stratific = source_dataloarder.dataset.get_stratification()
src_rgb_samples, src_depth_samples = source_dataloarder.dataset.sample_images(stratific, n_samples=250)
tgt_rgb_samples, tgt_depth_samples = test_target_dataloarder.dataset.sample_images(stratific, n_samples=250)

# Extract source-only best model
_, _, _, _, _, _, _, _, so_checkpoints = load_so_checkpoint(prefix="8")
checkpoint = so_checkpoints[0]
so_extractor = checkpoint['Extractor']
so_classifier = checkpoint['mainTask']
# Extract source features
plottable_so_source = visualizer.features_2d(src_rgb_samples, src_depth_samples, so_extractor, so_classifier)
# Extract target features
plottable_so_target = visualizer.features_2d(tgt_rgb_samples, tgt_depth_samples, so_extractor, so_classifier)

# Domain Adaptation best model
_, _, _, _, _, _, _, _, _, _, da_checkpoints = load_da_checkpoint(prefix="2")
checkpoint = da_checkpoints[0]
da_extractor = checkpoint['Extractor']
da_classifier = checkpoint['mainTask']
# Extract source features
plottable_da_source = visualizer.features_2d(src_rgb_samples, src_depth_samples, da_extractor, da_classifier)
# Extract target features
plottable_da_target = visualizer.features_2d(tgt_rgb_samples, tgt_depth_samples, da_extractor, da_classifier)

# Plot the results

# Source-only
fig, ax = plt.subplots(figsize=(12,10))
plt.axis('off')
plt.title("2D representation of features, source-only baseline")
ax.scatter(plottable_so_source[:,0], plottable_so_source[:,1], label="Source data")
ax.scatter(plottable_so_target[:,0], plottable_so_target[:,1], label="Target data")
ax.legend()
plt.show()

# DA
fig, ax = plt.subplots(figsize=(12,10))
plt.axis('off')
plt.title("2D representation of features, with DA")
ax.scatter(plottable_da_source[:,0], plottable_da_source[:,1], label="Source data")
ax.scatter(plottable_da_target[:,0], plottable_da_target[:,1], label="Target data")
ax.legend()
plt.show()

(rgb_batch, depth_batch), _ = iter(test_target_dataloarder).next()

visualizer.saliency_maps(rgb_batch[0].to(DEVICE), depth_batch[0].to(DEVICE), da_extractor, da_classifier)

"""**--- VARIATION ---**

**Variation implementation**

Setup:
"""

# select which variation to apply:
second_variation = SECOND_VARIATION
# False --> do the first experiment: guess if it's the same permut for both images
# True --> do the second experiment: guess which permut was applied to both

if second_variation == False:
  num_cl = 1
  print("Model set up for first variation")
else:
  num_cl = 6
  prefix = str(prefix) + "bis"
  print("Model set up for second variation")

Extractor = FeatureExtractor().to(DEVICE)
mainTask = MainTask().to(DEVICE)
preText = PreText_variation(num_classes=num_cl).to(DEVICE)

extractor_opt = optim.SGD(Extractor.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
mainTask_opt = optim.SGD(mainTask.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
preText_opt = optim.SGD(preText.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)

"""**Define checkpoint methods**"""

"""
v_checkpoint = {'Extractor': Extractor,
                'mainTask': mainTask,
                'preText': preText,
          'Extractor_state_dict': Extractor.state_dict(),
          'mainTask_state_dict': mainTask.state_dict(),
          'preText_state_dict': preText.state_dict(),
                'extractor_opt': extractor_opt,
                'mainTask_opt': mainTask_opt,
                'preText_opt': preText_opt,
          'Extractor_optimizer' : extractor_opt.state_dict(),
          'mainTask_optimizer' : mainTask_opt.state_dict(),
          'preText_optimizer' : preText_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
"""

DRIVEPATH = "/content/drive/My Drive/"
LOCALPATH = "/content/checkpoints/"
V_CHECKPOINT = "v_checkpoint.pth"

# Function loading a checkpoint
def load_v_checkpoint(prefix=""):

  if not os.path.isdir("/content/checkpoints"): # create destination
    !mkdir /content/checkpoints
  
  if os.path.exists(DRIVEPATH+str(prefix)+V_CHECKPOINT) and os.path.isfile(DRIVEPATH+str(prefix)+V_CHECKPOINT): # if f existst and is a file
    shutil.copyfile(DRIVEPATH+str(prefix)+V_CHECKPOINT, LOCALPATH+str(prefix)+V_CHECKPOINT)                     # copy it locally
  else:
    sys.exit(-1)
  
  checkpoint = torch.load(LOCALPATH+str(prefix)+V_CHECKPOINT)                                        # load it from local copy

  Extractor = checkpoint['Extractor']
  mainTask = checkpoint['mainTask']
  preText = checkpoint['preText']
  extractor_opt = checkpoint['extractor_opt']
  mainTask_opt = checkpoint['mainTask_opt']
  preText_opt = checkpoint['preText_opt']

  Extractor.load_state_dict(checkpoint['Extractor_state_dict'])
  mainTask.load_state_dict(checkpoint['mainTask_state_dict'])
  preText.load_state_dict(checkpoint['preText_state_dict'])
  extractor_opt.load_state_dict(checkpoint['Extractor_optimizer'])
  mainTask_opt.load_state_dict(checkpoint['mainTask_optimizer'])
  preText_opt.load_state_dict(checkpoint['preText_optimizer'])

  print(f"Restored checkpoint at epoch: {checkpoint['epoch']}")

  return Extractor, mainTask, preText, extractor_opt, mainTask_opt, preText_opt,\
         checkpoint['epoch'], checkpoint['lossesLists'], checkpoint['val_accuracy'], checkpoint['additional_data'], checkpoint['main_checkpoints']


def save_v_checkpoint(checkpoint, prefix=""):

  if not os.path.isdir("/content/checkpoints"): # create source
    !mkdir /content/checkpoints                 
    
  torch.save(checkpoint, LOCALPATH+str(prefix)+V_CHECKPOINT)

  if os.path.exists(DRIVEPATH): # if f existst and is a file
    shutil.copyfile(LOCALPATH+str(prefix)+V_CHECKPOINT, DRIVEPATH+str(prefix)+V_CHECKPOINT) # copy it locally
    print("Checkpoint saved")
  else:
    sys.exit(-1)

"""Load a checkpoint"""

# this is use for the back up
# WARNING: run this block only if you want to load the saved parameters (OVERWRITES PREVIOUS CELLS)
Extractor, mainTask, preText, extractor_opt, mainTask_opt, preText_opt, ELAPSED_DA_EPOCHS, lossesLists,\
                                            val_accuracy, additional_data, main_checkpoints = load_v_checkpoint(prefix=prefix)
V_RESTORED = True

"""Train:"""

# Losses
mainTask_criterion = nn.CrossEntropyLoss() # criterion Lm
if second_variation == False:
  preText_criterion = nn.BCEWithLogitsLoss()  # criterion Lp
else:
  preText_criterion = nn.CrossEntropyLoss()  # criterion Lp

# 
# Entropy loss for the target on main task
def tgt_main_criterion(logits):
    p_softmax = F.softmax(logits, dim=1)
    mask = p_softmax.ge(0.000001)  # greater or equal to, used for numerical stability
    mask_out = torch.masked_select(p_softmax, mask)
    entropy = -(torch.sum(mask_out * torch.log(mask_out)))
    return entropy / float(p_softmax.size(0))

import PIL
from PIL import Image
start_time = time.time()
 
cudnn.benchmark                                    # Calling this optimizes runtime
 
if V_RESTORED:                                    # if a checkpoint was loaded
  Src_mainLoss = lossesLists[0]                       # restore the previous losses lists
  tgt_mainLoss = lossesLists[1]
  Src_rotateLoss = lossesLists[2]
  tgt_rotateLoss = lossesLists[3]
  epochs_no_improve = additional_data[0]
  min_val_loss = additional_data[1]
  best_epoch = additional_data[2]
  # val_accuracy is already restored
  # main_checkpoints is already restored
else:                                              # otherwise use some new ones
  Src_mainLoss = []
  tgt_mainLoss = []
  Src_rotateLoss = []
  tgt_rotateLoss = []
  val_accuracy = []
  epochs_no_improve = 0
  min_val_loss = np.Inf
  best_epoch = 0
  main_checkpoints = []
 
 
n_epochs_stop = EARLY_STOP_VAL
flag_stop = False
epoch = ELAPSED_DA_EPOCHS + 1

while epoch <= NUM_EPOCHS:
  if flag_stop == True:
    break
  print('Starting epoch {}/{}'.format(epoch , NUM_EPOCHS))
 
  # Data loaders:
  source_rotated_dataloader,target_rotated_dataloader = get_permuted_dataLoader(data_synRODrgb,\
                                                    data_synRODdepth, data_RODrgb, data_RODdepth, second_variation)
  
  torch.cuda.empty_cache()
  Extractor.train(True)                                 # set in training mode
  mainTask.train(True)                                  # set in training mode
  preText.train(True)                                   # set in training mode
 
  cumsum_mainloss = 0
  cumsum_T_mainloss = 0
  cumsum_Trloss = 0
  cumsum_Srloss = 0
  current_step = 0
 
  # Work on 3 batches in parallel
  for S, T, Sr, Tr in zip(source_dataloarder, train_target_dataloarder, source_rotated_dataloader, target_rotated_dataloader):
 
    # Forward pass - Source:
    (S_rgb_image, S_depth_image), S_label = S                 # load Source batch
 
    S_rgb_batch = S_rgb_image.to(DEVICE)                      # bring data over device
    S_depth_batch = S_depth_image.to(DEVICE)                  # bring data over device
    S_label = S_label.to(DEVICE)                              # bring label over device
 
    S_features = Extractor.forward(S_rgb_batch, S_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(S_features)                 # main task forward pass
    S_main_loss = mainTask_criterion(outPuts_main, S_label)       # compute main loss
    cumsum_mainloss += S_main_loss.item()*len(S_rgb_image)        # loss for all the images in S_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE --> Step {}, Loss {}'.format(current_step, S_main_loss.item()))
 
 
 
    # Forward pass - Target:
    (T_rgb_image, T_depth_image), T_label = T                 # load Source batch
 
    T_rgb_batch = T_rgb_image.to(DEVICE)                      # bring data over device
    T_depth_batch = T_depth_image.to(DEVICE)                  # bring data over device
                                                              # DON'T use the labels
 
    T_features = Extractor.forward(T_rgb_batch, T_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(T_features)                 # main task forward pass
    T_main_loss = tgt_main_criterion(outPuts_main)              # compute main loss of Target on MainTask
    cumsum_T_mainloss += T_main_loss.item()*len(T_rgb_image)           # loss for all the images in T_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('TARGET --> Step {}, Loss {}'.format(current_step, T_main_loss.item()))
 
 
 
    # Forward pass - Source permutated
    (Sr_rgb_image, Sr_depth_image), Sr_label = Sr               # load Source rotated batch

    Sr_rgb_batch = Sr_rgb_image.to(DEVICE)                      # bring data over device
    Sr_depth_batch = Sr_depth_image.to(DEVICE)                  # bring data over device
    Sr_label = Sr_label.to(DEVICE)                              # bring label over device
 
    Sr_features = Extractor.forward(Sr_rgb_batch, Sr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Sr_features)                     # preText task forward pass

    if second_variation == False:
      out_preText = out_preText[:, 0]                                # reshape it from [64,1] to [64] for BCELoss
      #Sr_loss = preText_criterion(out_preText, Sr_label)         # compute aux loss 
      Sr_loss = preText_criterion(torch.tensor(out_preText, dtype=torch.float32), torch.tensor(Sr_label, dtype=torch.float32))
      #Sr_loss = preText_criterion(torch.tensor(torch.argmax(out_preText, axis=1), dtype=torch.float32), torch.tensor(Sr_label, dtype=torch.float32))
    else:
      Sr_loss = preText_criterion(out_preText, Sr_label)

    cumsum_Srloss += Sr_loss.item()*len(Sr_rgb_image)              # loss for all the images in Sr_rgb_image
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE PERM --> Step {}, Loss {}'.format(current_step, Sr_loss.item()))
 
 
 
    # Forward pass - Target rotated
    (Tr_rgb_image, Tr_depth_image), Tr_label = Tr               # load Source rotated batch
 
    Tr_rgb_batch = Tr_rgb_image.to(DEVICE)                      # bring data over device
    Tr_depth_batch = Tr_depth_image.to(DEVICE)                  # bring data over device
    Tr_label = Tr_label.to(DEVICE)                              # bring the label to device 
 
    Tr_features = Extractor.forward(Tr_rgb_batch, Tr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Tr_features)                     # preText task forward pass

    if second_variation == False:
      out_preText = out_preText[:, 0]                                # reshape it from [64,1] to [64] for BCELoss
      Tr_loss = preText_criterion(torch.tensor(out_preText, dtype=torch.float32), torch.tensor(Tr_label, dtype=torch.float32))
      #Tr_loss = preText_criterion(out_preText.argmax(axis=1), Tr_label)                   # compute aux loss (entropy loss)
    #Tr_loss = preText_criterion(torch.tensor(torch.argmax(out_preText, axis=1), dtype=torch.float32), torch.tensor(Tr_label, dtype=torch.float32))
    else:
      Tr_loss = preText_criterion(out_preText, Tr_label)

    cumsum_Trloss += Tr_loss.item()*len(Tr_rgb_image)              # loss for all the images in Tr_rgb_image
 
    if current_step % LOG_FREQUENCY == 0:
      print('TARGET PERM --> Step {}, Loss {}'.format(current_step, Tr_loss.item()))
 
 
    # computing final loss
    final_loss = S_main_loss + LAMBDA1 * (Sr_loss +  Tr_loss) + LAMBDA2 * T_main_loss
 
    if current_step % LOG_FREQUENCY == 0:
      print('TOTAL LOSS --> Step {}, Loss {}'.format(current_step, final_loss.item()))
      print()
 
    # final steps
    Extractor.zero_grad()             # Zero-ing the gradients
    mainTask.zero_grad()              # Zero-ing the gradients
    preText.zero_grad()               # Zero-ing the gradients
 
    final_loss.backward()             # backward pass: computes gradients for the net
 
    preText_opt.step()                # update weights for pretext
    extractor_opt.step()              # update weights for extractor
    mainTask_opt.step()               # update the weights of the only maintask
 
    current_step += 1
  
 
  #list of losses for the source dataset over the main classifier for later visualization
  Src_mainLoss.append(cumsum_mainloss / float(len(source_dataloarder.dataset))) 
  tgt_mainLoss.append(cumsum_T_mainloss / float(len(train_target_dataloarder.dataset))) 
  Src_rotateLoss.append(cumsum_Srloss / float(len( source_rotated_dataloader.dataset)))
  tgt_rotateLoss.append(cumsum_Trloss / float(len(target_rotated_dataloader.dataset)))
 
 
  # each 5 epochs do a complete validation/test phase on the target dataset
  #otherwise do it on 100 batches only for all the other epochs
  """big_test = False
  if epoch != 0 and epoch % 5 == 0:
    big_test = True"""
  # Not entirely representative of the actual performance in quick validations. Let's do a complete one each epoch
  big_test = True
 
  loss , acc = validation_test(Extractor, mainTask, test_target_dataloarder, mainTask_criterion, test_phase = big_test)
  val_accuracy.append(acc)
  print(f"\nVALIDATION ACCURACY: {acc}")
  print(f"VALIDATION Loss: {loss}")
 
 
  # early stopping criterion
  if loss < min_val_loss:       # if there was an improvement in the loss --> reset counter
    epochs_no_improve = 0
    min_val_loss = loss
    best_epoch = epoch
  else:                       # Otherwise increment count of epochs with no improvement
    epochs_no_improve += 1
    # Check early stopping condition
    if epochs_no_improve >= n_epochs_stop:
      print(f'\nEarly stopping! at epoch {epoch}.\n The best epoch is epoch {best_epoch}')
      flag_stop = True
 
 
  # save the model at each epoch end
  lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss] # list of losses lists
  additional_data = [epochs_no_improve, min_val_loss, best_epoch]            # list of important params to save
  
  checkpoint = {'Extractor': Extractor,
                'mainTask': mainTask,
                'preText': preText,
          'Extractor_state_dict': Extractor.state_dict(),
          'mainTask_state_dict': mainTask.state_dict(),
          'preText_state_dict': preText.state_dict(),
                'extractor_opt': extractor_opt,
                'mainTask_opt': mainTask_opt,
                'preText_opt': preText_opt,
          'Extractor_optimizer' : extractor_opt.state_dict(),
          'mainTask_optimizer' : mainTask_opt.state_dict(),
          'preText_optimizer' : preText_opt.state_dict(),
                'epoch': epoch,
                'lossesLists': lossesLists,
                'val_accuracy' : val_accuracy,
                'additional_data': additional_data,
                'main_checkpoints': main_checkpoints}
 
  if epoch != 0 and epoch % 5 == 0:
    # each 5 epochs save the checkpoint in the main checkpoints list
    main_checkpoint = dict()  # create an independent copy
    for k in checkpoint:
      if k != 'main_checkpoints': # clear this for memory purposes
        main_checkpoint[k] = checkpoint[k]
      else:
        main_checkpoint[k] = None

    checkpoint['main_checkpoints'].append(main_checkpoint)
 
  save_v_checkpoint(checkpoint, prefix=prefix)
  
  # save the checkpoint
  
  exec_time = time.time() - start_time
  mins = int(exec_time // 60)
  secs = int(exec_time % 60)
  print(f"--- Elapsed time from trainig start (eventual checkpoint restoration excluded): {mins} minutes and {secs} seconds ---\n")
  epoch +=1
  # --- epoch end ---

"""Results"""

# Variation results

models_to_plot = [13,14,15] 


colorlist = ['black', 'gray', 'lightcoral', 
'saddlebrown', 'red', 'darkorange', 
'gold', 'olivedrab', 'lime', 
'turquoise', 'dodgerblue', 'darkslateblue',
'blueviolet', 'violet', 'yellow']

curves = []

for i in models_to_plot: 
  
  #standard variation (1)
  prefix = str(i)

  _, _, _, _, _, _, _, lossesList1, val_accuracy, _, main_checkpoints = load_v_checkpoint(prefix)

  best_acc = max(val_accuracy)
  best_epoch = val_accuracy.index(best_acc)+1

  label = f"Model {i} (best {(best_acc // 0.0001)/100} at epoch {best_epoch})"

  screenshot = {'x': range(1, len(val_accuracy)+1), 'y': val_accuracy, 
                'label': label, 'color': colorlist[i - min(models_to_plot)]}

  curves.append(screenshot)

  #lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss]
  # losses of variation 1
  text = label
  losses = list()

  labls = ['Src-mainTask', 'Tgt-mainTask', 'Src-permuted','Tgt-permuted']
  c = 0
  for l in lossesList1:

    label = labls[c]

    screenshot = {'x': range(1, len(l)+1), 'y': l, 
                  'label': label, 'color': colorlist[c]}

    losses.append(screenshot)

    c += 1
  big_plot(losses, f"{text}: Losses variation 1", "Loss")


  #second variation (2)
  prefix = prefix + 'bis'

  _, _, _, _, _, _, _, lossesList2, val_accuracy, _, main_checkpoints = load_v_checkpoint(prefix)

  best_acc = max(val_accuracy)
  best_epoch = val_accuracy.index(best_acc)+1

  label = f"Model {prefix} (best {(best_acc // 0.0001)/100} at epoch {best_epoch})"

  screenshot = {'x': range(1, len(val_accuracy)+1), 'y': val_accuracy, 
                'label': label, 'color': colorlist[len(colorlist)-1-(i - min(models_to_plot))]}

  curves.append(screenshot)

  #lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss]
  # losses of variation 2
  text = label
  losses = list()

  labls = ['Src-mainTask', 'Tgt-mainTask', 'Src-permuted','Tgt-permuted']
  c = 0
  for l in lossesList2:

    label = labls[c]

    screenshot = {'x': range(1, len(l)+1), 'y': l, 
                  'label': label, 'color': colorlist[c]}

    losses.append(screenshot)

    c += 1
  big_plot(losses, f"{text}: Losses variation 2", "Loss")

big_plot(curves, "Variation models performances")


commented_stuff = """#lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss]
# losses of variation 1
losses = list()

labls = ['Src-mainTask', 'Tgt-mainTask', 'Src-permuted','Tgt-permuted']
c = 0
for l in lossesList1:

  label = labls[c]

  screenshot = {'x': range(1, len(l)+1), 'y': l, 
                'label': label, 'color': colorlist[c]}

  losses.append(screenshot)

  c += 1
#big_plot(losses, "Losses variation 1", "Loss")



#lossesLists = [Src_mainLoss, tgt_mainLoss, Src_rotateLoss, tgt_rotateLoss]
# losses of variation 2
losses = list()

labls = ['Src-mainTask', 'Tgt-mainTask', 'Src-permuted','Tgt-permuted']
c = 0
for l in lossesList2:

  label = labls[c]

  screenshot = {'x': range(1, len(l)+1), 'y': l, 
                'label': label, 'color': colorlist[c]}

  losses.append(screenshot)

  c += 1
#big_plot(losses, "Losses variation 2", "Loss")"""

"""**Variation 1 - further experiments**"""

def pretext_test(extractor, maintask, dataloader, criterion, test_phase):
  # i perform the model evaluation after each epoch
  running_corrects = 0
  loss_val = 0.0
  extractor.eval()
  maintask.eval()
  batch_n = 0

  with torch.no_grad():
    for (rgb, depth), labels in tqdm(dataloader):
      batch_n += 1
      rgb = rgb.to(DEVICE)
      depth = depth.to(DEVICE)
      labels = labels.to(DEVICE)
      #make predictions
      features = extractor.forward(rgb, depth)
      outputs = maintask.forward(features)
      outputs = outputs[:, 0]                                # reshape it from [64,1] to [64] for BCELoss
      print(outputs.shape)
      Tr_loss = criterion(torch.tensor(outputs, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32))
      #get the validation loss for each batch
      loss_val += Tr_loss.item()*len(rgb)
      # Get predictions
      preds = (outputs)   
      mask = (preds > 0) # i.e. sigmoid(preds) > 0.5
      preds[mask] = 1
      preds[~mask] = 0
      preds = torch.tensor(preds)

      # Update Corrects
      running_corrects += torch.sum(preds == labels.data).data.item()
      # stop at batch number 100 if test_phase = True
      if batch_n == NUM_BATCHES_LIMITED and test_phase == False:
        break

  if test_phase == False:
    length = NUM_BATCHES_LIMITED*BATCH_SIZE
  else:
    length = len(dataloader.dataset)
  
  return float(loss_val)/ float(length), float(running_corrects)/ float(length)

import PIL
from PIL import Image
start_time = time.time()
 
Extractor = FeatureExtractor().to(DEVICE)
mainTask = MainTask().to(DEVICE)
preText = PreText_variation(num_classes=1).to(DEVICE)

extractor_opt = optim.SGD(Extractor.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
mainTask_opt = optim.SGD(mainTask.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)
preText_opt = optim.SGD(preText.parameters(), lr = LR, momentum = MOMENTUM, weight_decay=WEIGHT_DECAY)

cudnn.benchmark                                    # Calling this optimizes runtime
 
Src_mainLoss = []
tgt_mainLoss = []
Src_rotateLoss = []
tgt_rotateLoss = []
val_accuracy = []
epochs_no_improve = 0
min_val_loss = np.Inf
best_epoch = 0

big_test = True
n_epochs_stop = EARLY_STOP_VAL
flag_stop = False
epoch = ELAPSED_DA_EPOCHS + 1

# Evaluate initial level of the model
# main task
_, acc1 = validation_test(Extractor, mainTask, test_target_dataloarder, mainTask_criterion, test_phase = big_test)
# pretext task
source_permuted_dataloader,target_permuted_dataloader = get_permuted_dataLoader(data_synRODrgb,\
                                                    data_synRODdepth, data_RODrgb, data_RODdepth, second_variation)
loss , acc = pretext_test(Extractor, preText, target_permuted_dataloader, preText_criterion, test_phase = big_test)
# print
print(f"Initial main task accuracy on target, without any training: {acc1}")
print(f"Initial pretext task accuracy on target: {acc}\nInitial loss value for it: {loss}")
ptx_losses = [loss]
ptx_acc = [acc]

while epoch <= NUM_EPOCHS:
  if flag_stop == True:
    break
  print('Starting epoch {}/{}'.format(epoch , NUM_EPOCHS))
 
  # Data loaders:
  source_rotated_dataloader,target_rotated_dataloader = get_permuted_dataLoader(data_synRODrgb,\
                                                    data_synRODdepth, data_RODrgb, data_RODdepth, second_variation)
  
  torch.cuda.empty_cache()
  Extractor.train(True)                                 # set in training mode
  mainTask.train(True)                                  # set in training mode
  preText.train(True)                                   # set in training mode
 
  cumsum_mainloss = 0
  cumsum_T_mainloss = 0
  cumsum_Trloss = 0
  cumsum_Srloss = 0
  current_step = 0
 
  # Work on 3 batches in parallel
  for S, T, Sr, Tr in zip(source_dataloarder, train_target_dataloarder, source_rotated_dataloader, target_rotated_dataloader):
 
    # Forward pass - Source:
    (S_rgb_image, S_depth_image), S_label = S                 # load Source batch
 
    S_rgb_batch = S_rgb_image.to(DEVICE)                      # bring data over device
    S_depth_batch = S_depth_image.to(DEVICE)                  # bring data over device
    S_label = S_label.to(DEVICE)                              # bring label over device
 
    S_features = Extractor.forward(S_rgb_batch, S_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(S_features)                 # main task forward pass
    S_main_loss = mainTask_criterion(outPuts_main, S_label)       # compute main loss
    cumsum_mainloss += S_main_loss.item()*len(S_rgb_image)        # loss for all the images in S_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE --> Step {}, Loss {}'.format(current_step, S_main_loss.item()))
 
 
 
    # Forward pass - Target:
    (T_rgb_image, T_depth_image), T_label = T                 # load Source batch
 
    T_rgb_batch = T_rgb_image.to(DEVICE)                      # bring data over device
    T_depth_batch = T_depth_image.to(DEVICE)                  # bring data over device
                                                              # DON'T use the labels
 
    T_features = Extractor.forward(T_rgb_batch, T_depth_batch)  # Forward pass (feature extractor)
    outPuts_main = mainTask.forward(T_features)                 # main task forward pass
    T_main_loss = tgt_main_criterion(outPuts_main)              # compute main loss of Target on MainTask
    cumsum_T_mainloss += T_main_loss.item()*len(T_rgb_image)           # loss for all the images in T_rgb_image 
 
    if current_step % LOG_FREQUENCY == 0:
      print('TARGET --> Step {}, Loss {}'.format(current_step, T_main_loss.item()))
 
 
 
    # Forward pass - Source rotated
    (Sr_rgb_image, Sr_depth_image), Sr_label = Sr               # load Source rotated batch

    Sr_rgb_batch = Sr_rgb_image.to(DEVICE)                      # bring data over device
    Sr_depth_batch = Sr_depth_image.to(DEVICE)                  # bring data over device
    Sr_label = Sr_label.to(DEVICE)                              # bring label over device
 
    Sr_features = Extractor.forward(Sr_rgb_batch, Sr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Sr_features)                     # preText task forward pass

    out_preText = out_preText[:, 0]                                # reshape it from [64,1] to [64] for BCELoss
    #Sr_loss = preText_criterion(out_preText, Sr_label)         # compute aux loss 
    Sr_loss = preText_criterion(torch.tensor(out_preText, dtype=torch.float32), torch.tensor(Sr_label, dtype=torch.float32))
    #Sr_loss = preText_criterion(torch.tensor(torch.argmax(out_preText, axis=1), dtype=torch.float32), torch.tensor(Sr_label, dtype=torch.float32))

    cumsum_Srloss += Sr_loss.item()*len(Sr_rgb_image)              # loss for all the images in Sr_rgb_image
 
    if current_step % LOG_FREQUENCY == 0:
      print('SOURCE PERM --> Step {}, Loss {}'.format(current_step, Sr_loss.item()))
 
 
 
    # Forward pass - Target rotated
    (Tr_rgb_image, Tr_depth_image), Tr_label = Tr               # load Source rotated batch
 
    Tr_rgb_batch = Tr_rgb_image.to(DEVICE)                      # bring data over device
    Tr_depth_batch = Tr_depth_image.to(DEVICE)                  # bring data over device
    Tr_label = Tr_label.to(DEVICE)                              # bring the label to device 
 
    Tr_features = Extractor.forward(Tr_rgb_batch, Tr_depth_batch)  # Forward pass (feature extractor)
    out_preText = preText.forward(Tr_features)                     # preText task forward pass

    
    out_preText = out_preText[:, 0]                                # reshape it from [64,1] to [64] for BCELoss
    Tr_loss = preText_criterion(torch.tensor(out_preText, dtype=torch.float32), torch.tensor(Tr_label, dtype=torch.float32))

    cumsum_Trloss += Tr_loss.item()*len(Tr_rgb_image)              # loss for all the images in Tr_rgb_image
 
    print('TARGET PERM --> Step {}, Loss {}'.format(current_step, Tr_loss.item()))
    ptx_losses.append(Tr_loss.item())
 
    # computing final loss
    final_loss = S_main_loss + LAMBDA1 * (Sr_loss +  Tr_loss) + LAMBDA2 * T_main_loss
 
    if current_step % LOG_FREQUENCY == 0:
      print('TOTAL LOSS --> Step {}, Loss {}'.format(current_step, final_loss.item()))
      print()
 
    # final steps
    Extractor.zero_grad()             # Zero-ing the gradients
    mainTask.zero_grad()              # Zero-ing the gradients
    preText.zero_grad()               # Zero-ing the gradients
 
    final_loss.backward()             # backward pass: computes gradients for the net
 
    preText_opt.step()                # update weights for pretext
    extractor_opt.step()              # update weights for extractor
    mainTask_opt.step()               # update the weights of the only maintask
 
    current_step += 1
  
 
  #list of losses for the source dataset over the main classifier for later visualization
  Src_mainLoss.append(cumsum_mainloss / float(len(source_dataloarder.dataset))) 
  tgt_mainLoss.append(cumsum_T_mainloss / float(len(train_target_dataloarder.dataset))) 
  Src_rotateLoss.append(cumsum_Srloss / float(len( source_rotated_dataloader.dataset)))
  tgt_rotateLoss.append(cumsum_Trloss / float(len(target_rotated_dataloader.dataset)))
 
 
  # each 5 epochs do a complete validation/test phase on the target dataset
  #otherwise do it on 100 batches only for all the other epochs
  """big_test = False
  if epoch != 0 and epoch % 5 == 0:
    big_test = True"""
  # Not entirely representative of the actual performance in quick validations. Let's do a complete one each epoch
  big_test = True
 
  loss1 , acc1 = validation_test(Extractor, mainTask, test_target_dataloarder, mainTask_criterion, test_phase = big_test)
  val_accuracy.append(acc)

  loss , acc = pretext_test(Extractor, preText, target_permuted_dataloader, preText_criterion, test_phase = big_test)
  print(f"\nVALIDATION ACCURACY: {acc1}")
  print(f"VALIDATION Loss: {loss1}")
  print(f"PRETEXT ACCURACY: {acc}\n")
  ptx_acc.append(acc)
 
 
  # early stopping criterion
  if loss < min_val_loss:       # if there was an improvement in the loss --> reset counter
    epochs_no_improve = 0
    min_val_loss = loss
    best_epoch = epoch
  else:                       # Otherwise increment count of epochs with no improvement
    epochs_no_improve += 1
    # Check early stopping condition
    if epochs_no_improve >= n_epochs_stop:
      print(f'\nEarly stopping! at epoch {epoch}.\n The best epoch is epoch {best_epoch}')
      flag_stop = True
 
  exec_time = time.time() - start_time
  mins = int(exec_time // 60)
  secs = int(exec_time % 60)
  print(f"--- Elapsed time from trainig start (eventual checkpoint restoration excluded): {mins} minutes and {secs} seconds ---\n")
  epoch +=1
  # --- epoch end ---

#def simple_plot(x, y, title=None, x_label=None, y_label=None)
simple_plot([i for i in range(len(ptx_losses))], ptx_losses, title="Pretext loss behavior on target at each step", x_label="number of elapsed steps", y_label="loss values")

simple_plot([i for i in range(len(ptx_acc))], ptx_acc, title="Pretext accuracy on target at each epoch", x_label="number of elapsed epochs", y_label="accuracy")

# Variation 1
_, _, _, _, _, _, _, _, _, _, v1_checkpoints = load_v_checkpoint(prefix="15")
checkpoint = v1_checkpoints[0]
v1_extractor = checkpoint['Extractor']
v1_classifier = checkpoint['mainTask']
# Extract source features
plottable_v1_source = visualizer.features_2d(src_rgb_samples, src_depth_samples, v1_extractor, v1_classifier)
# Extract target features
plottable_v1_target = visualizer.features_2d(tgt_rgb_samples, tgt_depth_samples, v1_extractor, v1_classifier)

# Variation 2
_, _, _, _, _, _, _, _, _, _, v2_checkpoints = load_v_checkpoint(prefix="15bis")
checkpoint = v2_checkpoints[0]
v2_extractor = checkpoint['Extractor']
v2_classifier = checkpoint['mainTask']
# Extract source features
plottable_v2_source = visualizer.features_2d(src_rgb_samples, src_depth_samples, v2_extractor, v2_classifier)
# Extract target features
plottable_v2_target = visualizer.features_2d(tgt_rgb_samples, tgt_depth_samples, v2_extractor, v2_classifier)

# Plot the results

# V1
fig, ax = plt.subplots(figsize=(12,10))
plt.axis('off')
plt.title("2D representation of features, variation 1 (binary)")
ax.scatter(plottable_v1_source[:,0], plottable_v1_source[:,1], label="Source data")
ax.scatter(plottable_v1_target[:,0], plottable_v1_target[:,1], label="Target data")
ax.legend()
plt.show()

# V2
fig, ax = plt.subplots(figsize=(12,10))
plt.axis('off')
plt.title("2D representation of features, variation 2 (6 classes)")
ax.scatter(plottable_v2_source[:,0], plottable_v2_source[:,1], label="Source data")
ax.scatter(plottable_v2_target[:,0], plottable_v2_target[:,1], label="Target data")
ax.legend()
plt.show()